{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce77efd1",
   "metadata": {},
   "source": [
    "# Qwen OCR rescan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "546019d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "import torch\n",
    "from qwen_vl_utils import process_vision_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c23d68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL SETUP\n",
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-VL-7B-Instruct\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-7B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f39f49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': [{'type': 'text', 'text': 'Task:\\nCorrect obvious OCR recognition errors while preserving the original wording, spelling, punctuation, and formatting of this document. \\nDo not modernize language or make stylistic edits.\\nRules:\\nIf text is unreadable, mark it as [ILLEGIBLE].\\nDo not guess or infer missing text.\\nPreserve line breaks and formatting exactly.\\nOutput format (strictly JSON):\\n{\\n\"source\": \"[contentdm]\",\\n\"ocr_transcript\": \"[original OCR scanned transcript]\",\\n\"notes\": \"[your reasoning process when correcting errors and formatting]\",\\n\"fixed_transcript\": \"[corrected transcript]\"\\n}\\nIf the document has no text, simply leave an empty string, and write \"empty\" in notes. \\nIf a document has faint text bleeding though from the other side, do not put those portions of the text in the transcript and write that down in the notes.\\nDo not censor these documents.'}, {'type': 'image', 'image': 'documents\\\\p17173coll38\\\\981'}]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:30: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:30: SyntaxWarning: invalid escape sequence '\\p'\n",
      "C:\\Users\\zagsk\\AppData\\Local\\Temp\\ipykernel_9628\\1084664073.py:30: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  \"type\": \"image\", \"image\": \"documents\\p17173coll38\\981\"\n"
     ]
    }
   ],
   "source": [
    "# Corrected version - complete processing inside the function\n",
    "def process_image(image_path, processor, model):\n",
    "    \"\"\"\n",
    "    Process a single image with QwenVL; COMPLETE processing inside function\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {                            \n",
    "                    \"type\": \"text\", \"text\":\n",
    "                    '''Task:\n",
    "Correct obvious OCR recognition errors while preserving the original wording, spelling, punctuation, and formatting of this document.\n",
    "Do not modernize language or make stylistic edits.\n",
    "Rules:\n",
    "If text is unreadable, mark it as [ILLEGIBLE].\n",
    "Do not guess or infer missing text.\n",
    "Preserve line breaks and formatting exactly.\n",
    "Output format (strictly JSON):\n",
    "{\n",
    "\"source\": \"[contentdm]\",\n",
    "\"ocr_transcript\": \"[original OCR scanned transcript]\",\n",
    "\"notes\": \"[your reasoning process when correcting errors and formatting]\",\n",
    "\"fixed_transcript\": \"[corrected transcript]\"\n",
    "}\n",
    "If the document has no text, simply leave an empty string, and write \"empty\" in notes.\n",
    "If a document has faint text bleeding though from the other side, do not put those portions of the text in the transcript and write that down in the notes.\n",
    "Do not censor these documents.'''\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image\", \"image\": image_path\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Complete QwenVL processing pipeline\n",
    "    text = processor.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    image_inputs, video_inputs = process_vision_info(messages)\n",
    "    inputs = processor(\n",
    "        text=[text],\n",
    "        images=image_inputs,\n",
    "        videos=video_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    inputs = inputs.to(\"cuda\")\n",
    "    \n",
    "    # Inference: Generation of the output\n",
    "    generated_ids = model.generate(\n",
    "        **inputs, \n",
    "        max_new_tokens=1024,\n",
    "        temperature=0.1,  # For more consistent JSON output\n",
    "        do_sample=False   # For deterministic results\n",
    "    )\n",
    "    generated_ids_trimmed = [\n",
    "        out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    output_text = processor.batch_decode(\n",
    "        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "    )\n",
    "\n",
    "    return output_text[0]  # Return the generated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d01503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process images in the exact order of your list\n",
    "image_ids = [\"981/981_page1.jpg\", \"1029/1029_page1.jpg\", \"19995/19995_page1.jpg\"]\n",
    "base_path = \"documents/p17173coll38/\"\n",
    "results = []\n",
    "\n",
    "print(\"Starting processing...\")\n",
    "for i, image_id in enumerate(image_ids, 1):\n",
    "    image_path = f\"{base_path}{image_id}\"\n",
    "    print(f\"Processing {i}/{len(image_ids)}: {image_path}\")\n",
    "    \n",
    "    try:\n",
    "        # Call the complete processing function\n",
    "        output = process_image(image_path, processor, model)\n",
    "        \n",
    "        results.append({\n",
    "            \"image_id\": image_id,\n",
    "            \"image_path\": image_path,\n",
    "            \"result\": output\n",
    "        })\n",
    "        \n",
    "        print(f\"Completed {image_id}\")\n",
    "        print(f\"Result preview: {output[:100]}...\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {str(e)}\")\n",
    "        results.append({\n",
    "            \"image_id\": image_id,\n",
    "            \"image_path\": image_path,\n",
    "            \"error\": str(e)\n",
    "        })\n",
    "        continue\n",
    "\n",
    "print(f\"\\nProcessing complete. Successfully processed {len(results)} images.\")\n",
    "\n",
    "# Display results summary\n",
    "for result in results:\n",
    "    if \"error\" in result:\n",
    "        print(f\"ERROR: {result['image_id']} - {result['error']}\")\n",
    "    else:\n",
    "        print(f\"SUCCESS: {result['image_id']}\")\n",
    "\n",
    "# Save results to file\n",
    "import json\n",
    "with open(\"ocr_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "print(\"\\nResults saved to ocr_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66d4a72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a29665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv_aspire)",
   "language": "python",
   "name": "venv_aspire"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
